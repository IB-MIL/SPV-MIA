The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) nvidia/.latest   2) slurm/.latest
/fred/oz413/.conda/envs/llm-env/lib/python3.10/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(
/fred/oz413/.conda/envs/llm-env/lib/python3.10/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(
Traceback (most recent call last):
  File "/fred/oz413/ANeurIPS2024_SPV-MIA/attack.py", line 53, in <module>
    target_model = AutoModelForCausalLM.from_pretrained(cfg["target_model"], quantization_config=BitsAndBytesConfig(load_in_8bit=True),
  File "/fred/oz413/.conda/envs/llm-env/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 565, in from_pretrained
    return model_class.from_pretrained(
  File "/fred/oz413/.conda/envs/llm-env/lib/python3.10/site-packages/transformers/modeling_utils.py", line 3380, in from_pretrained
    model.load_adapter(
  File "/fred/oz413/.conda/envs/llm-env/lib/python3.10/site-packages/transformers/integrations/peft.py", line 187, in load_adapter
    inject_adapter_in_model(peft_config, self, adapter_name)
  File "/fred/oz413/.conda/envs/llm-env/lib/python3.10/site-packages/peft/mapping.py", line 134, in inject_adapter_in_model
    peft_model = tuner_cls(model, peft_config, adapter_name=adapter_name)
  File "/fred/oz413/.conda/envs/llm-env/lib/python3.10/site-packages/peft/tuners/lora.py", line 274, in __init__
    super().__init__(model, config, adapter_name)
  File "/fred/oz413/.conda/envs/llm-env/lib/python3.10/site-packages/peft/tuners/tuners_utils.py", line 88, in __init__
    self.inject_adapter(self.model, adapter_name)
  File "/fred/oz413/.conda/envs/llm-env/lib/python3.10/site-packages/peft/tuners/tuners_utils.py", line 219, in inject_adapter
    self._create_and_replace(peft_config, adapter_name, target, target_name, parent, **optionnal_kwargs)
  File "/fred/oz413/.conda/envs/llm-env/lib/python3.10/site-packages/peft/tuners/lora.py", line 372, in _create_and_replace
    new_module = self._create_new_module(lora_config, adapter_name, target, **kwargs)
  File "/fred/oz413/.conda/envs/llm-env/lib/python3.10/site-packages/peft/tuners/lora.py", line 428, in _create_new_module
    "memory_efficient_backward": target.state.memory_efficient_backward,
AttributeError: 'MatmulLtState' object has no attribute 'memory_efficient_backward'
