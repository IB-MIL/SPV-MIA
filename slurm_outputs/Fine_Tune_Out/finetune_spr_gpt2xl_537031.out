Job Started: Thu May 22 19:52:15 AEST 2025
Job ID: 537031
Running on node(s): gina6
Allocated CPUs: 8
Allocated Memory: 65536 MB
Allocated GPU(s) Raw: 1 (using GRES: )
CUDA_VISIBLE_DEVICES: 0
Attempting to load system Mamba module...
Conda (mamba) command found at: conda ()
{ 
    \local cmd="${1-__missing__}";
    case "$cmd" in 
        activate | deactivate)
            __conda_activate "$@"
        ;;
        install | update | upgrade | remove | uninstall)
            __conda_exe "$@" || \return;
            __conda_reactivate
        ;;
        *)
            __conda_exe "$@"
        ;;
    esac
}
Activating Conda env: llm-env
Python location: /fred/oz413/.conda/envs/llm-env/bin/python
Python version: Python 3.10.16
PyTorch CUDA available: True
Number of GPUs PyTorch sees: 1
Thu May 22 19:53:37 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.124.06             Driver Version: 570.124.06     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-80GB          On  |   00000000:41:00.0 Off |                    0 |
| N/A   25C    P0             58W /  500W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Working directory: /fred/oz413/ANeurIPS2024_SPV-MIA
Launching training with Accelerate...
[05/22/25 19:56:26] INFO     Model is not llama, disabling  llms_finetune.py:102
                             flash attention...                                 
                    INFO     Pad token id is None, setting  llms_finetune.py:136
                             to eos token id...                                 
                    INFO     Using a block size of 128      llms_finetune.py:140
                    INFO     Using no quantization          llms_finetune.py:158
[05/22/25 19:56:51] INFO     Using PEFT...                  llms_finetune.py:199
                    INFO     Getting PEFT model...          llms_finetune.py:207
trainable params: 19660800 || all params: 1577272000 || trainable%: 1.2465066266312976
DEBUG: args object in dataset_prepare: Namespace(model_name='gpt2-xl', dataset_name='ag_news', dataset_config_name='default', cache_path='./cache', use_dataset_cache=True, refer=False, refer_data_source=None, packing=True, token=None, split_model=False, block_size=128, preprocessing_num_workers=1, peft='lora', lora_rank=64, lora_alpha=16, lora_dropout=0.1, p_tokens=20, p_hidden=128, learning_rate=5e-05, lr_scheduler_type='linear', warmup_steps=0, weight_decay=0, output_dir='./ft_llms/gpt2-xl/ag_news/baseline/', log_steps=100, eval_steps=100, save_epochs=100, epochs=2, batch_size=4, gradient_accumulation_steps=1, gradient_checkpointing=False, trust_remote_code=False, train_sta_idx=0, train_end_idx=10000, eval_sta_idx=0, eval_end_idx=1000, save_limit=None, use_int4=False, use_int8=False, disable_peft=False, disable_flash_attention=False, pad_token_id=None, add_eos_token=False, add_bos_token=False, validation_split_percentage=0.1)
Found dataset at specific config path: /fred/oz413/LLM/ag_news/default
Loading dataset from disk: /fred/oz413/LLM/ag_news/default
Identified text column as: 'text'
Applying text packing...
Folder './cache/ag_news/default' already exists.
Folder './cache/ag_news/default' already exists.
[05/22/25 19:56:55] INFO     Training with 1 GPUs           llms_finetune.py:228
{'loss': 3.7244, 'learning_rate': 4.9e-05, 'epoch': 0.04}
{'eval_loss': 3.5695526599884033, 'eval_runtime': 8.5777, 'eval_samples_per_second': 116.582, 'eval_steps_per_second': 14.573, 'epoch': 0.04}
ERROR: llms_finetune.py failed with exit code 1
Job Ended: Thu May 22 19:57:47 AEST 2025

+-------------------- Job Report: 537031 (FAILED) ---------------------+
| Memory (RAM)  [##                  ] 10.2% (6.5 GB peak / 64 GB)     |
| CPU           [                    ]  1.6% average                   |
| GPU           [                    ]  0.0% average                   |
| Time          [->                  ]  9.6% (0-00:05:45 / 0-01:00:00) |
|                                                                      |
| Lustre Filesystem:                                                   |
|   Path    Total Read    Total Write    Total IOPS                    |
|   ------  ------------  -------------  ------------                  |
|   /apps   32 MB         0 B            2 K                           |
|   /fred   1 GB          24.7 KB        24.7 K                        |
|   /home   8 KB          0 B            12                            |
|   OS      143 MB        0 B            43                            |
|                                                                      |
| Warnings:                                                            |
|   - Too much memory requested                                        |
|   - CPU usage is low                                                 |
|   - GPU usage is low                                                 |
|   - Too much time requested                                          |
+----------------------------------------------------------------------+
