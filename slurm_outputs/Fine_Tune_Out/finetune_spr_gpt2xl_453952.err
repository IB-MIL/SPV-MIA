The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) nvidia/.latest   2) slurm/.latest
-------------------------------------------------------------------------------
There are messages associated with the following module(s):
-------------------------------------------------------------------------------

mamba:
   - Mamba is a drop-in replacement for conda, offering higher speed and
   more reliable environment solutions. - Do you really need conda/mamba??
   Do you know about python virtual environments??? We HIGHLY recommend
   using virtual envs instead. e.g. python -m venv my-environment - Remember
   you can change where conda environemnts are created (if you run out of
   space in your home directory) ``` $ conda config --env --prepend
   envs_dirs /path/to/my/project/on/fred/.conda/envs $ conda config --env
   --prepend pkgs_dirs /path/to/my/project/on/fred/.conda/pkgs ``` - To hide
   this message in the future, load the module with -q ``` $ module -q load
   conda ```

-------------------------------------------------------------------------------

/fred/oz413/.conda/envs/llm-env/lib/python3.10/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(
The following values were not passed to `accelerate launch` and had defaults used instead:
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
/fred/oz413/.conda/envs/llm-env/lib/python3.10/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(
/fred/oz413/.conda/envs/llm-env/lib/python3.10/site-packages/accelerate/accelerator.py:437: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  self.scaler = torch.cuda.amp.GradScaler(**kwargs)
/fred/oz413/.conda/envs/llm-env/lib/python3.10/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(
/fred/oz413/.conda/envs/llm-env/lib/python3.10/site-packages/peft/tuners/lora.py:475: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.
  warnings.warn(
/fred/oz413/.conda/envs/llm-env/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:166: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024
  warnings.warn(
Map:   0%|          | 0/10000 [00:00<?, ? examples/s]Map:  10%|█         | 1000/10000 [00:00<00:01, 8510.29 examples/s]Map:  30%|███       | 3000/10000 [00:00<00:00, 10501.07 examples/s]Map:  50%|█████     | 5000/10000 [00:00<00:00, 10967.60 examples/s]Map:  70%|███████   | 7000/10000 [00:00<00:00, 11190.97 examples/s]Map:  90%|█████████ | 9000/10000 [00:00<00:00, 11249.83 examples/s]Map: 100%|██████████| 10000/10000 [00:00<00:00, 10998.87 examples/s]
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 11408.63 examples/s]
wandb: Network error (ProxyError), entering retry loop.
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
wandb: Network error (ProxyError), entering retry loop.
wandb: ERROR Run initialization has timed out after 90.0 sec. Please try increasing the timeout with the `init_timeout` setting: `wandb.init(settings=wandb.Settings(init_timeout=120))`.
Traceback (most recent call last):
  File "/fred/oz413/.conda/envs/llm-env/lib/python3.10/asyncio/locks.py", line 214, in wait
    await fut
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/fred/oz413/.conda/envs/llm-env/lib/python3.10/asyncio/tasks.py", line 456, in wait_for
    return fut.result()
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/fred/oz413/.conda/envs/llm-env/lib/python3.10/site-packages/wandb/sdk/mailbox/response_handle.py", line 109, in wait_async
    await asyncio.wait_for(evt.wait(), timeout=timeout)
  File "/fred/oz413/.conda/envs/llm-env/lib/python3.10/asyncio/tasks.py", line 458, in wait_for
    raise exceptions.TimeoutError() from exc
asyncio.exceptions.TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/fred/oz413/.conda/envs/llm-env/lib/python3.10/site-packages/wandb/sdk/wandb_init.py", line 1055, in init
    result = wait_with_progress(
  File "/fred/oz413/.conda/envs/llm-env/lib/python3.10/site-packages/wandb/sdk/mailbox/wait_with_progress.py", line 24, in wait_with_progress
    return wait_all_with_progress(
  File "/fred/oz413/.conda/envs/llm-env/lib/python3.10/site-packages/wandb/sdk/mailbox/wait_with_progress.py", line 87, in wait_all_with_progress
    return asyncio_compat.run(progress_loop_with_timeout)
  File "/fred/oz413/.conda/envs/llm-env/lib/python3.10/site-packages/wandb/sdk/lib/asyncio_compat.py", line 30, in run
    return future.result()
  File "/fred/oz413/.conda/envs/llm-env/lib/python3.10/concurrent/futures/_base.py", line 458, in result
    return self.__get_result()
  File "/fred/oz413/.conda/envs/llm-env/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/fred/oz413/.conda/envs/llm-env/lib/python3.10/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/fred/oz413/.conda/envs/llm-env/lib/python3.10/site-packages/wandb/sdk/lib/asyncio_compat.py", line 74, in run
    return asyncio.run(self._run_or_cancel(fn))
  File "/fred/oz413/.conda/envs/llm-env/lib/python3.10/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/fred/oz413/.conda/envs/llm-env/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/fred/oz413/.conda/envs/llm-env/lib/python3.10/site-packages/wandb/sdk/lib/asyncio_compat.py", line 98, in _run_or_cancel
    return fn_task.result()
  File "/fred/oz413/.conda/envs/llm-env/lib/python3.10/site-packages/wandb/sdk/mailbox/wait_with_progress.py", line 82, in progress_loop_with_timeout
    return await _wait_handles_async(
  File "/fred/oz413/.conda/envs/llm-env/lib/python3.10/site-packages/wandb/sdk/mailbox/wait_with_progress.py", line 130, in _wait_handles_async
    async with asyncio_compat.open_task_group() as task_group:
  File "/fred/oz413/.conda/envs/llm-env/lib/python3.10/contextlib.py", line 206, in __aexit__
    await anext(self.gen)
  File "/fred/oz413/.conda/envs/llm-env/lib/python3.10/site-packages/wandb/sdk/lib/asyncio_compat.py", line 190, in open_task_group
    await task_group._wait_all()
  File "/fred/oz413/.conda/envs/llm-env/lib/python3.10/site-packages/wandb/sdk/lib/asyncio_compat.py", line 159, in _wait_all
    raise exc
  File "/fred/oz413/.conda/envs/llm-env/lib/python3.10/site-packages/wandb/sdk/mailbox/wait_with_progress.py", line 128, in wait_single
    results[index] = await handle.wait_async(timeout=timeout)
  File "/fred/oz413/.conda/envs/llm-env/lib/python3.10/site-packages/wandb/sdk/mailbox/mailbox_handle.py", line 126, in wait_async
    response = await self._handle.wait_async(timeout=timeout)
  File "/fred/oz413/.conda/envs/llm-env/lib/python3.10/site-packages/wandb/sdk/mailbox/response_handle.py", line 118, in wait_async
    raise TimeoutError(
TimeoutError: Timed out waiting for response on 874oc4yxk4uw

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/fred/oz413/ANeurIPS2024_SPV-MIA/./ft_llms/llms_finetune.py", line 269, in <module>
    trainer.train()
  File "/fred/oz413/.conda/envs/llm-env/lib/python3.10/site-packages/transformers/trainer.py", line 1591, in train
    return inner_training_loop(
  File "/fred/oz413/.conda/envs/llm-env/lib/python3.10/site-packages/transformers/trainer.py", line 1826, in _inner_training_loop
    self.control = self.callback_handler.on_train_begin(args, self.state, self.control)
  File "/fred/oz413/.conda/envs/llm-env/lib/python3.10/site-packages/transformers/trainer_callback.py", line 362, in on_train_begin
    return self.call_event("on_train_begin", args, state, control)
  File "/fred/oz413/.conda/envs/llm-env/lib/python3.10/site-packages/transformers/trainer_callback.py", line 406, in call_event
    result = getattr(callback, event)(
  File "/fred/oz413/.conda/envs/llm-env/lib/python3.10/site-packages/transformers/integrations/integration_utils.py", line 766, in on_train_begin
    self.setup(args, state, model, **kwargs)
  File "/fred/oz413/.conda/envs/llm-env/lib/python3.10/site-packages/transformers/integrations/integration_utils.py", line 740, in setup
    self._wandb.init(
  File "/fred/oz413/.conda/envs/llm-env/lib/python3.10/site-packages/wandb/sdk/wandb_init.py", line 1691, in init
    wandb._sentry.reraise(e)
  File "/fred/oz413/.conda/envs/llm-env/lib/python3.10/site-packages/wandb/analytics/sentry.py", line 156, in reraise
    raise exc.with_traceback(sys.exc_info()[2])
  File "/fred/oz413/.conda/envs/llm-env/lib/python3.10/site-packages/wandb/sdk/wandb_init.py", line 1677, in init
    return wi.init(run_settings, run_config, run_printer)
  File "/fred/oz413/.conda/envs/llm-env/lib/python3.10/site-packages/wandb/sdk/wandb_init.py", line 1068, in init
    raise CommError(
wandb.errors.errors.CommError: Run initialization has timed out after 90.0 sec. Please try increasing the timeout with the `init_timeout` setting: `wandb.init(settings=wandb.Settings(init_timeout=120))`.
slurmstepd: error: *** JOB 453952 ON gina14 CANCELLED AT 2025-05-19T17:26:14 DUE TO TIME LIMIT ***
